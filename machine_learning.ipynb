{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine learning",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtorTmRM3EKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import cv2 \n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from func_hair import smplextract_hair\n",
        "from PIL import Image\n",
        "from sklearn.metrics import jaccard_score\n",
        "import pdb\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pyfeats import fos\n",
        "import pandas as pd\n",
        "from skimage import filters\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "from sklearn.utils.estimator_checks import check_estimator\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from scipy import interp\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import RFECV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import csv\n",
        "header = ['mean_R', 'std_R', 'skew_R', 'mean_G',  'std_G',  'skew_G',  'mean_B',  'std_B',  'skew_B',   \n",
        "                 'mean_H', 'std_H', 'skew_H', 'mean_S',  'std_S',  'skew_S',  'mean_V',  'std_V', 'skew_V',              \n",
        "                 'CM_black', 'CM_red', 'CM_bluegray', 'CM_white', 'CM_lightbrown', 'CM_darkbrown' \n",
        "               \n",
        "                 'mean_ccR', 'std_ccR', 'skew_ccR', 'mean_ccG',  'std_ccG',  'skew_ccG',  'mean_ccB',  'std_ccB',  'skew_ccB', \n",
        "                 'mean_ccH', 'std_ccH', 'skew_ccH', 'mean_ccS',  'std_ccS',  'skew_ccS',  'mean_ccV',  'std_ccV',  'skew_ccV',\n",
        "                 'mean_mxR', 'std_mxR', 'skew_mxR', 'mean_mxG',  'std_mxG',  'skew_mxG',  'mean_mxB',  'std_mxB',  'skew_mxB', \n",
        "                 'mean_mxH', 'std_mxH', 'skew_mxH', 'mean_mxS',  'std_mxS',  'skew_mxS',  'mean_mxV',  'std_mxV',  'skew_mxV',\n",
        "                 'contrast0','contrast1','contrast2','dissimilarity0','dissimilarity1','dissimilarity2','correlation0','correlation1','correlation2','homogeneity0','homogeneity1','homogeneity2',\n",
        "                 'contrast0h','contrast1s','contrast2v','dissimilarity0h','dissimilarity1s','dissimilarity2v','correlation0h','correlation1s','correlation2v','homogeneity0h','homogeneity1s','homogeneity2v']\n",
        "with open('features.csv1','w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "\n",
        "pathFolder_train='/home/nisma/data1/'\n",
        "train_Array = [x for x in sorted(os.listdir(pathFolder_train)) if os.path.isfile(os.path.join(pathFolder_train,x))]\n",
        "outputFolder_path='/home/nisma/save2/'\n",
        "\n",
        "def segmentation(img_o):\n",
        "    h1,w1,c1=img_o.shape\n",
        "   \n",
        "    resized_down = cv2.resize(img_o, (256,192), interpolation= cv2.INTER_AREA)\n",
        "   \n",
        "    img_r= smplextract_hair(resized_down)\n",
        "   \n",
        "\n",
        "    median = cv2.medianBlur(img_r,5) # Apply Median filter\n",
        "    # =============================================================================\n",
        "    #  \n",
        "\n",
        "    Z = median.reshape((-1,3))\n",
        "\n",
        "    # convert to np.float32\n",
        "    Z = np.float32(Z)\n",
        "\n",
        "    # define criteria, number of clusters(K) and apply kmeans()\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    K = 8\n",
        "    flags=cv2.KMEANS_RANDOM_CENTERS\n",
        "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,flags)\n",
        "\n",
        "    # Now convert back into uint8, and make original image\n",
        "    center = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    kmeans_img = res.reshape((img_r.shape))\n",
        "    # =============================================================================\n",
        "    # =============================================================================\n",
        "    #    Adaptive histogram equalization  \n",
        "    # =============================================================================\n",
        "    clahe = cv2.createCLAHE(clipLimit=3., tileGridSize=(8,8))\n",
        "\n",
        "    hsv = cv2.cvtColor(kmeans_img, cv2.COLOR_BGR2HSV)# convert from BGR to HSV color space\n",
        "    \n",
        "     \n",
        "    h, s, v = cv2.split(hsv)  # split on 3 different channels\n",
        "    #apply CLAHE to the L-channel\n",
        "    h1 = clahe.apply(h)\n",
        "    s1 = clahe.apply(s)\n",
        "    v1 = clahe.apply(v)\n",
        "    lab = cv2.merge((h1,s1,v1))  # merge channels\n",
        "    Enhance_img= cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
        "     \n",
        "    # =============================================================================\n",
        "    #    making the mask for grabcut\n",
        "    # =============================================================================\n",
        "    hsv = cv2.cvtColor(Enhance_img, cv2.COLOR_BGR2HSV)    \n",
        "    lower_green = np.array([50,100,100])\n",
        "    upper_green = np.array([150,255,255])\n",
        "    #lower_green = np.array([150,100,100])\n",
        "    #upper_green = np.array([150,250,255])\n",
        "    #mask_g = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    #cv2.imshow(\"1ramask\",mask_g)\n",
        "    mask_g = cv2.inRange(hsv, lower_green, upper_green)     \n",
        "    ret,inv_mask = cv2.threshold(mask_g,127,255,cv2.THRESH_BINARY_INV)     \n",
        "    res = cv2.bitwise_and(img_r,img_r, mask= mask_g)\n",
        "    mask = np.zeros(img_r.shape[:2],np.uint8)\n",
        "    bgdModel = np.zeros((1,65),np.float64)\n",
        "    fgdModel = np.zeros((1,65),np.float64)\n",
        "   \n",
        "    # =============================================================================\n",
        "    #      GRABCUT\n",
        "    # =============================================================================\n",
        "    if (np.sum(inv_mask[:])<8507940):\n",
        "        newmask = inv_mask\n",
        "\n",
        "        # wherever it is marked white (sure foreground), change mask=1\n",
        "        # wherever it is marked black (sure background), change mask=0\n",
        "        mask[newmask == 0] = 0\n",
        "        mask[newmask == 255] = 1\n",
        "        #dim2= cv2.grabCut(lab,mask,None,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_MASK)\n",
        "        mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "        GrabCut_img2 = img_r*mask2[:,:,np.newaxis]\n",
        "        \n",
        "    else:\n",
        "        s = (img_r.shape[0] / 10, img_r.shape[1] / 10)\n",
        "        rect = (int(s[0]), int(s[1]), int(img_r.shape[0]) -int((3/10)) * int(s[0]), int(img_r.shape[1]) - int(s[1]))\n",
        "        cv2.grabCut(lab,mask,rect,bgdModel,fgdModel,10,cv2.GC_INIT_WITH_RECT)\n",
        "        mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "        GrabCut_img2= img_r*mask2[:,:,np.newaxis]\n",
        "        \n",
        "     \n",
        "\n",
        "    # =============================================================================\n",
        "    # Binarization\n",
        "    # =============================================================================\n",
        "    imgmask2 = cv2.medianBlur(GrabCut_img2,5)\n",
        "    ret,Segmented_mask2 = cv2.threshold(imgmask2,0,255,cv2.THRESH_BINARY)\n",
        "    print(\"segggg\", Segmented_mask2.shape)\n",
        "    ##cv2.imshow(\"seg\",Segmented_mask2)\n",
        "    return Segmented_mask2,img_r\n",
        "    # =================================================\n",
        "\n",
        "### Color Features\n",
        "def color_moments(image, channel=3):\n",
        "    if (channel==3):        \n",
        "        mean_0 = np.mean(image[:,:,0])\n",
        "        mean_1 = np.mean(image[:,:,1])\n",
        "        mean_2 = np.mean(image[:,:,2])\n",
        "        std_0  = np.std(image[:,:,0])\n",
        "        std_1  = np.std(image[:,:,1])\n",
        "        std_2  = np.std(image[:,:,2])\n",
        "        skew_0 = skew(image[:,:,0].reshape(-1))\n",
        "        skew_1 = skew(image[:,:,1].reshape(-1))\n",
        "        skew_2 = skew(image[:,:,2].reshape(-1))\n",
        "        kurt_0 = kurtosis(image[:,:,0].reshape(-1))\n",
        "        kurt_1 = kurtosis(image[:,:,1].reshape(-1))\n",
        "        kurt_2 = kurtosis(image[:,:,2].reshape(-1))\n",
        "        return mean_0, std_0, skew_0, kurt_0, mean_1, std_1, skew_1, kurt_1, mean_2, std_2, skew_2, kurt_2\n",
        "\n",
        "    \n",
        "    else:\n",
        "        assert False, \"ERROR: The function supports only 1 or 3-channel image formats.\"\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "def GLCM(image, channel=3, bit_depth=8):\n",
        "    if (channel==3):  \n",
        "        GLCM_0  = graycomatrix(image[:,:,0],  [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=2**bit_depth)\n",
        "        GLCM_1  = graycomatrix(image[:,:,1],  [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=2**bit_depth)\n",
        "        GLCM_2  = graycomatrix(image[:,:,2],  [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=2**bit_depth)\n",
        "        contrast_0  = graycoprops(GLCM_0,  'contrast').mean()\n",
        "        contrast_1  = graycoprops(GLCM_1,  'contrast').mean()\n",
        "        contrast_2  = graycoprops(GLCM_2,  'contrast').mean()\n",
        "        dissim_0    = graycoprops(GLCM_0,  'dissimilarity').mean()\n",
        "        dissim_1    = graycoprops(GLCM_1,  'dissimilarity').mean()\n",
        "        dissim_2    = graycoprops(GLCM_2,  'dissimilarity').mean()     \n",
        "        correl_0    = graycoprops(GLCM_0,  'correlation').mean()\n",
        "        correl_1    = graycoprops(GLCM_1,  'correlation').mean()\n",
        "        correl_2    = graycoprops(GLCM_2,  'correlation').mean()\n",
        "        homo_0      = graycoprops(GLCM_0,  'homogeneity').mean()\n",
        "        homo_1      = graycoprops(GLCM_1,  'homogeneity').mean()\n",
        "        homo_2      = graycoprops(GLCM_2,  'homogeneity').mean()\n",
        "        return [ contrast_0, dissim_0, correl_0, homo_0, contrast_1, dissim_1,\n",
        "                 correl_1, homo_1, contrast_2, dissim_2, correl_2, homo_2 ]\n",
        "    \n",
        "    else:\n",
        "        assert False, \"ERROR: The function supports only 1 or 3-channel image formats.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def melanoma_color_markers(image,mask):\n",
        "    CM_black      = np.count_nonzero(((image[:,:,0].astype(float)/255)<0.20)\n",
        "                                    &((image[:,:,1].astype(float)/255)<0.20)\n",
        "                                    &((image[:,:,2].astype(float)/255)<0.20))*(100/np.sum(mask))\n",
        "    CM_red        = np.count_nonzero(((image[:,:,0].astype(float)/255)>0.80)\n",
        "                                    &((image[:,:,1].astype(float)/255)<0.20)\n",
        "                                    &((image[:,:,2].astype(float)/255)<0.20))*(100/np.sum(mask))\n",
        "    CM_bluegray   = np.count_nonzero(((image[:,:,0].astype(float)/255)<0.20)\n",
        "                                    &((image[:,:,1].astype(float)/255)<0.72)\n",
        "                                    &((image[:,:,1].astype(float)/255)>0.30)\n",
        "                                    &((image[:,:,2].astype(float)/255)<0.74)\n",
        "                                    &((image[:,:,2].astype(float)/255)>0.34))*(100/np.sum(mask))\n",
        "    CM_white      = np.count_nonzero(((image[:,:,0].astype(float)/255)>0.80)\n",
        "                                    &((image[:,:,1].astype(float)/255)>0.80)\n",
        "                                    &((image[:,:,2].astype(float)/255)>0.80))*(100/np.sum(mask))\n",
        "    CM_lightbrown = np.count_nonzero(((image[:,:,0].astype(float)/255)<1.00)\n",
        "                                    &((image[:,:,0].astype(float)/255)>0.60)\n",
        "                                    &((image[:,:,1].astype(float)/255)<0.72)\n",
        "                                    &((image[:,:,1].astype(float)/255)>0.32)\n",
        "                                    &((image[:,:,2].astype(float)/255)<0.45)\n",
        "                                    &((image[:,:,2].astype(float)/255)>0.05))*(100/np.sum(mask))\n",
        "    CM_darkbrown  = np.count_nonzero(((image[:,:,0].astype(float)/255)<0.60)\n",
        "                                    &((image[:,:,0].astype(float)/255)>0.20)\n",
        "                                    &((image[:,:,1].astype(float)/255)<0.46)\n",
        "                                    &((image[:,:,1].astype(float)/255)>0.06)\n",
        "                                    &((image[:,:,2].astype(float)/255)<0.33))*(100/np.sum(mask))\n",
        "    return CM_black, CM_red, CM_bluegray, CM_white, CM_lightbrown, CM_darkbrown\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def LBP(image, channel=3, P=8, R=2, bins=10):\n",
        "    if (channel==3):\n",
        "        lbp       = local_binary_pattern(image[:,:,0], P=P, R=R, method=\"uniform\")\n",
        "        lbp_0, _  = np.histogram(lbp, density=True, bins=bins, range=(0,int(lbp.max()+1)))\n",
        "        lbp       = local_binary_pattern(image[:,:,1], P=P, R=R, method=\"uniform\")\n",
        "        lbp_1, _  = np.histogram(lbp, density=True, bins=bins, range=(0,int(lbp.max()+1)))\n",
        "        lbp       = local_binary_pattern(image[:,:,2], P=P, R=R, method=\"uniform\")\n",
        "        lbp_2, _  = np.histogram(lbp, density=True, bins=bins, range=(0,int(lbp.max()+1)))\n",
        "        return lbp_0, lbp_1, lbp_2\n",
        "\n",
        "    else:\n",
        "        assert False, \"ERROR: The function supports only 1 or 3-channel image formats.\"\n",
        "\n",
        "        \n",
        "#############################################################################################################################################################\n",
        "### Feature Extraction\n",
        "def grey_edge(image, njet=0, mink_norm=1, sigma=1):\n",
        "\n",
        "    gauss_image = filters.gaussian(image, sigma=sigma, multichannel=True)\n",
        "\n",
        "    if njet == 0:\n",
        "        deriv_image = [gauss_image[:, :, channel] for channel in range(3)]\n",
        "    else:   \n",
        "        if njet == 1:\n",
        "            deriv_filter = filters.sobel\n",
        "        elif njet == 2:\n",
        "            deriv_filter = filters.laplace\n",
        "        else:\n",
        "            raise ValueError(\"njet should be in range[0-2]! Given value is: \" + str(njet))     \n",
        "        deriv_image = [np.abs(deriv_filter(gauss_image[:, :, channel])) for channel in range(3)]\n",
        "\n",
        "    for channel in range(3):\n",
        "        deriv_image[channel][image[:, :, channel] >= 255] = 0.\n",
        "\n",
        "    if mink_norm == -1:  \n",
        "        estimating_func = np.max \n",
        "    else:\n",
        "        estimating_func = lambda x: np.power(np.sum(np.power(x, mink_norm)), 1 / mink_norm)\n",
        "    illum = [estimating_func(channel) for channel in deriv_image]\n",
        "    som   = np.sqrt(np.sum(np.power(illum, 2)))\n",
        "    illum = np.divide(illum, som)\n",
        "\n",
        "    return illum\n",
        "def correct_image(image, illum):\n",
        "    \"\"\"\n",
        "    Corrects image colors by performing diagonal transformation according to \n",
        "    given estimated illumination of the image.\n",
        "    \n",
        "    :param image: rgb input image (NxMx3)\n",
        "    :param illum: estimated illumination of the image\n",
        "    :return: corrected image\n",
        "    \"\"\"\n",
        "    correcting_illum = illum * np.sqrt(3)\n",
        "    corrected_image = image / 255.\n",
        "    for channel in range(3):\n",
        "        corrected_image[:, :, channel] /= correcting_illum[channel]\n",
        "    return np.clip(corrected_image, 0., 1.)\n",
        "def create_circular_mask(h, w, center=None, radius=None):\n",
        "    if center is None: # use the middle of the image\n",
        "        center = [int(w/2), int(h/2)]\n",
        "    if radius is None: # use the smallest distance between the center and image walls\n",
        "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
        "    Y, X = np.ogrid[:h, :w]\n",
        "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
        "    mask = dist_from_center <= radius\n",
        "    return mask\n",
        "def color_constant(img):\n",
        "    # Extract Color Channels\n",
        "    img_R = img[:,:,0]\n",
        "    img_G = img[:,:,1]\n",
        "    img_B = img[:,:,2]    \n",
        "    \n",
        "    # Calculate Channel Averages\n",
        "    avg_R = np.mean(img_R)\n",
        "    avg_G = np.mean(img_G)\n",
        "    avg_B = np.mean(img_B)\n",
        "    avg_all = np.mean(img)\n",
        "    \n",
        "    # Calculate Scaling Factor for White-Balance\n",
        "    scale_R = (avg_all / avg_R)\n",
        "    scale_G = (avg_all / avg_G)\n",
        "    scale_B = (avg_all / avg_B)\n",
        "    \n",
        "    # Transform to White-Balance\n",
        "    img_new = np.zeros(img.shape)\n",
        "    img_new[:,:,0] = scale_R * img_R  \n",
        "    img_new[:,:,1] = scale_G * img_G \n",
        "    img_new[:,:,2] = scale_B * img_B  \n",
        "    \n",
        "    # Normalize Images\n",
        "    max_intensity = np.max(np.max(np.max(img_new)))\n",
        "    min_intensity = np.min(np.min(np.min(img_new)))\n",
        "    \n",
        "    img_normalized = (((img_new - min_intensity) / (max_intensity - min_intensity))*255).astype(np.uint8)\n",
        "\n",
        "    # Illuminant Profile (Gray World Color Constancy) \n",
        "    illuminance = [avg_R, avg_G, avg_B]\n",
        "    \n",
        "    return img_normalized, illuminance\n",
        "def extract_features(image,mask=None):    \n",
        "    # Color Spaces: I/O ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    img_RGB               = image #original image \n",
        "    img_GL                = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2GRAY) #convert to grey\n",
        "    img_HSV               = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HSV) #convert to HSV\n",
        "\n",
        "    circa_mask            = create_circular_mask(image.shape[0], image.shape[1], radius = 300).astype(bool) # create circular mask around ROI\n",
        "    \n",
        "    #create masked lesions for three color spaces using above function\n",
        "    masked_lesion_GL      = np.ma.array(np.multiply(img_GL,    circa_mask)  ,mask=~circa_mask)\n",
        "    masked_lesion_RGB     = np.ma.array(np.multiply(img_RGB,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "    masked_lesion_HSV     = np.ma.array(np.multiply(img_HSV,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "    #-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    \n",
        "    # Color Constancy Spaces: I/O ---------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    #applying color constancy to detect the color of image independent of the light source and amount of varying illumination and image aquistaion methods\n",
        "    img_ccRGB,_           = color_constant(image)\n",
        "    img_ccGL              = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2GRAY)\n",
        "    img_ccHSV             = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    #masked lesions of CC \n",
        "    masked_lesion_ccGL    = np.ma.array(np.multiply(img_ccGL,    circa_mask)  ,mask=~circa_mask)\n",
        "    masked_lesion_ccRGB   = np.ma.array(np.multiply(img_ccRGB,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "    masked_lesion_ccHSV   = np.ma.array(np.multiply(img_ccHSV,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "\n",
        "    #masked lesions of CC max rgb normlaization\n",
        "    img_mxRGB             = (correct_image(image, grey_edge(image, njet=0, mink_norm=-1, sigma=0))*255).astype(np.uint8)\n",
        "    img_mxGL              = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2GRAY)\n",
        "    img_mxHSV             = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HSV)\n",
        "    \n",
        "    masked_lesion_mxGL    = np.ma.array(np.multiply(img_mxGL,    circa_mask)  ,mask=~circa_mask)\n",
        "    masked_lesion_mxRGB   = np.ma.array(np.multiply(img_mxRGB,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "    masked_lesion_mxHSV   = np.ma.array(np.multiply(img_mxHSV,   np.dstack((circa_mask,circa_mask,circa_mask))), mask=~np.dstack((circa_mask,circa_mask,circa_mask)))\n",
        "    #-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    \n",
        "    # Color Moments ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    #first order statistics of original image\n",
        "    mean_R, std_R, skew_R, kurt_R, mean_G,  std_G,  skew_G,  kurt_G,  mean_B,  std_B,  skew_B,  kurt_B   = color_moments(masked_lesion_RGB,     channel=3)\n",
        "    mean_H, std_H, skew_H, kurt_H, mean_S,  std_S,  skew_S,  kurt_S,  mean_V,  std_V,  skew_V,  kurt_V   = color_moments(masked_lesion_HSV,     channel=3)\n",
        "    #first order stats in gray world constancy\n",
        "    mean_ccR, std_ccR, skew_ccR, kurt_ccR, mean_ccG,  std_ccG,  skew_ccG,  kurt_ccG,  mean_ccB,  std_ccB,  skew_ccB,  kurt_ccB   = color_moments(masked_lesion_ccRGB,   channel=3)\n",
        "    mean_ccH, std_ccH, skew_ccH, kurt_ccH, mean_ccS,  std_ccS,  skew_ccS,  kurt_ccS,  mean_ccV,  std_ccV,  skew_ccV,  kurt_ccV   = color_moments(masked_lesion_ccHSV,   channel=3)\n",
        "    #first order stats in max rgb normalization\n",
        "    mean_mxR, std_mxR, skew_mxR, kurt_mxR, mean_mxG,  std_mxG,  skew_mxG,  kurt_mxG,  mean_mxB,  std_mxB,  skew_mxB,  kurt_mxB   = color_moments(masked_lesion_mxRGB,   channel=3)\n",
        "    mean_mxH, std_mxH, skew_mxH, kurt_mxH, mean_mxS,  std_mxS,  skew_mxS,  kurt_mxS,  mean_mxV,  std_mxV,  skew_mxV,  kurt_mxV   = color_moments(masked_lesion_mxHSV,   channel=3)\n",
        "    #low-level statistics-based methods like Grey-world (GW), MAX-RGB and Grey-Edge (GE)\n",
        "#     #-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # Graylevel Co-Occurrence Matrix -------------------------------------------------------------------------------------------------------------------------\n",
        "    GLCM_RGB   = GLCM(masked_lesion_RGB,   channel=3)\n",
        "    GLCM_HSV   = GLCM(masked_lesion_HSV,   channel=3)\n",
        "\n",
        "    #----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    \n",
        "    # Color Markers -------------------------------------------------------------------------------------------------------------\n",
        "    CM_black, CM_red, CM_bluegray, CM_white, CM_lightbrown, CM_darkbrown = melanoma_color_markers(masked_lesion_RGB, circa_mask)  \n",
        "    #-------------------------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    \n",
        "    # Local Binary Patterns --------------------------------------------------------------------------------------\n",
        "    lbp_R, lbp_G, lbp_B    = LBP(masked_lesion_RGB,   channel=3)\n",
        "    lbp_H, lbp_S, lbp_V    = LBP(masked_lesion_HSV,   channel=3)\n",
        "    \n",
        "    \n",
        "    LBP_CGLF  = np.concatenate((lbp_R,lbp_G,lbp_B,lbp_H,lbp_S,lbp_V),axis=0)\n",
        "   \n",
        "    #--------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    \n",
        "    #--------------------------------------------------------------------------------------------------------------    \n",
        "    \n",
        "               \n",
        "             \n",
        "    \n",
        "    features = [ mean_R, std_R, skew_R, mean_G,  std_G,  skew_G,  mean_B,  std_B,  skew_B,   \n",
        "                 mean_H, std_H, skew_H, mean_S,  std_S,  skew_S,  mean_V,  std_V,  skew_V,                  \n",
        "                 CM_black,CM_red, CM_bluegray, CM_white, CM_lightbrown, CM_darkbrown,\n",
        "                 mean_ccR, std_ccR, skew_ccR, mean_ccG,  std_ccG,  skew_ccG,  mean_ccB,  std_ccB,  skew_ccB, \n",
        "                 mean_ccH, std_ccH, skew_ccH, mean_ccS,  std_ccS,  skew_ccS,  mean_ccV,  std_ccV,  skew_ccV,                \n",
        "                 mean_mxR, std_mxR, skew_mxR, mean_mxG,  std_mxG,  skew_mxG,  mean_mxB,  std_mxB,  skew_mxB, \n",
        "                 mean_mxH, std_mxH, skew_mxH, mean_mxS,  std_mxS,  skew_mxS,  mean_mxV,  std_mxV,  skew_mxV]\n",
        "    features = np.concatenate((features, GLCM_RGB, GLCM_HSV, LBP_CGLF),axis=0)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def concat_and_shuffled(class0,class1, shuffled=True):\n",
        "    rnd = np.random.RandomState(8)\n",
        "    \n",
        "    # Create Individual Label Vectors\n",
        "    Y_0   = np.zeros(class0.shape[0])\n",
        "    Y_1   = np.ones(class1.shape[0])\n",
        "    \n",
        "    # Concatenate to Complete Vectors\n",
        "    Y     = np.concatenate([Y_0,Y_1])\n",
        "    X     = np.concatenate([class0,class1])\n",
        "    \n",
        "    if shuffled:\n",
        "        shuffled_indices = rnd.permutation(np.arange(Y.shape[0]))\n",
        "        return X[shuffled_indices], Y[shuffled_indices]\n",
        "    else:\n",
        "        return X, Y\n",
        "#############################################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################################################\n",
        "############################################## Training Images ################################################\n",
        "###############################################################################################################\n",
        "train_dat = dict()\n",
        "train_dat['feature'] = []\n",
        "train_dat['label'] = []\n",
        "temp=[]\n",
        "data = pd.read_csv('/home/nisma/final_labels1.csv')\n",
        "print(data.head())\n",
        "for i in range(0,2000):#range(len(train_Array)): \n",
        "    img_o=cv2.imread(pathFolder_train+train_Array[i])\n",
        "    print(train_Array[i])\n",
        "    img_seg,img_r = segmentation(img_o)\n",
        "    \n",
        "    h1,w1,c1=img_seg.shape\n",
        "    if img_seg[int(h1/2),int(w1/2)].all()==0:\n",
        "       img_seg=255-img_seg\n",
        "    \n",
        "    doctor = cv2.bitwise_and(img_r, img_seg, mask=None)\n",
        "    #resized\n",
        "    resized_up=cv2.resize(doctor, (img_o.shape[1],img_o.shape[0]), interpolation= cv2.INTER_AREA)\n",
        "    #print(doctor[24].shape)\n",
        "\n",
        "    cv2.imwrite(os.path.join(outputFolder_path+train_Array[i] ),resized_up)\n",
        "    features = extract_features(resized_up)\n",
        "    #converting features to list\n",
        "    m_list = features.tolist()\n",
        "    file = open('features.csv1', 'a', newline ='') \n",
        "    with file:     \n",
        "        write = csv.writer(file) \n",
        "        write.writerow(m_list) \n",
        "\n",
        "    if (data.loc[[i],[\"melanoma\"]].values==1):\n",
        "            train_dat['label'].append(1)\n",
        "            temp.append(features)\n",
        "    if (data.loc[[i],[\"seborrheic_keratosis\"]].values==1):\n",
        "            train_dat['label'].append(2)\n",
        "            \n",
        "            temp.append(features)\n",
        "    if (data.loc[[i],[\"benign\"]].values==1):\n",
        "            train_dat['label'].append(0)\n",
        "            temp.append(features)\n",
        "\n",
        "data_all = pd.DataFrame({\"Features\": temp, \"category\": train_dat['label']})\n",
        "print(data_all.head())\n",
        "###########################################################################################\n",
        "###########################################################################################\n",
        "#pdb.set_trace()\n",
        "X = np.array(temp)\n",
        "y = np.array(data_all[\"category\"])\n",
        "#  considering our we apply to data.\n",
        "#Firstly, I specify the random forest instance, indicating the number of trees.\n",
        "#Then I use selectFromModel object from sklearn to automatically select the features.\n",
        "# SelectFromModel is a meta-transformer that can be used alongside any estimator that assigns importance to each feature through a specific attribute\n",
        "#the unimportant features are removed according to threshold.\n",
        "#SelectFromModel will select those features which importance is greater than the mean importance of all the features by default, but we can alter this threshold if we want.\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X, y)\n",
        "# To see which features are important we can use get_support method on the fitted model.\n",
        "selected_feat= X[ :,(sel.get_support())]\n",
        "print(X.shape)\n",
        "#It will return an array of boolean values. True for the features whose importance is greater than the mean importance and False for the rest.\n",
        "print(selected_feat.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(selected_feat, y, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "# some time later...\n",
        "# load the model from disk\n",
        "\n",
        "'''loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)\n",
        "'''\n",
        "\n",
        "#Can also use SVM but RF is faster and may be more accurate.\n",
        "#from sklearn import svm\n",
        "\n",
        "###############################################################\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=2,\n",
        "                             n_jobs=1)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy = accuracy_score(model.predict(X_train), y_train)\n",
        "print(accuracy)\n",
        "\n",
        "n_neighbors = np.array([7,8,9,10,12,15,20])\n",
        "param_grid = dict(n_neighbors=n_neighbors)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.n_neighbors)\n",
        "y_pred1=grid.predict(X_test)\n",
        "print(classification_report(y_test, y_pred1))\n",
        "b=balanced_accuracy_score(y_test, y_pred1)\n",
        "print(\"balanced knn\",b)\n",
        "\n",
        "######################################################RF#####################################\n",
        "#RandomizedSearchCV implements a “fit” method and a “predict” method like any classifier except that the parameters of the classifier used to predict is optimized by cross-validation.\n",
        "n_estimators      = [int(x) for x in np.linspace(start=70, stop=250, num=25)]\n",
        "max_features      = ['auto', 'sqrt']\n",
        "max_depth         = [int(x) for x in np.linspace(start=5, stop=100, num=10)]\n",
        "min_samples_leaf  = [1, 2, 5, 10]\n",
        "min_samples_split = [2, 5, 10, 20]\n",
        "bootstrap         = [False]\n",
        "max_depth.append(None)\n",
        "random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth,\n",
        "                   'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
        "grid_search = RandomizedSearchCV(RandomForestClassifier(class_weight='balanced', random_state=0),\n",
        "                                     random_grid, n_iter=100, cv=5, random_state=0, n_jobs=-1)\n",
        "grid_search.fit(X_train,y_train)\n",
        "print(grid_search.best_params_)\n",
        "y_pred2=grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred2))\n",
        "b=balanced_accuracy_score(y_test, y_pred)\n",
        "print(\"balanced rf\",b)\n",
        "############################################################SVM#####################################\n",
        "n_estimators      = [int(x) for x in np.linspace(start=70, stop=250, num=25)]\n",
        "max_features      = ['auto', 'sqrt']\n",
        "max_depth         = [int(x) for x in np.linspace(start=5, stop=100, num=10)]\n",
        "min_samples_leaf  = [1, 2, 5, 10]\n",
        "min_samples_split = [2, 5, 10, 20]\n",
        "bootstrap         = [False]\n",
        "max_depth.append(None)\n",
        "random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth,\n",
        "                   'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
        "grid_search = RandomizedSearchCV(RandomForestClassifier(class_weight='balanced', random_state=0),\n",
        "                                     random_grid, n_iter=100, cv=5, random_state=0)\n",
        "grid_search.fit(X_train,y_train)\n",
        "print(grid_search.best_params_)\n",
        "y_pred2=grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred2))\n",
        "b=balanced_accuracy_score(y_test, y_pred2)\n",
        "print(\"balanced rf\",b)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8wPgB__4M4h",
        "outputId": "fc6cee4d-0b86-49bd-a4ae-b5db5ed93b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}